/*
 * <summary></summary>
 * <author>He Han</author>
 * <email>hankcs.cn@gmail.com</email>
 * <create-date>2014/5/10 12:42</create-date>
 *
 * <copyright file="WordDictionary.java" company="ä¸Šæµ·æž—åŽŸä¿¡æ?¯ç§‘æŠ€æœ‰é™?å…¬å?¸">
 * Copyright (c) 2003-2014, ä¸Šæµ·æž—åŽŸä¿¡æ?¯ç§‘æŠ€æœ‰é™?å…¬å?¸. All Right Reserved, http://www.linrunsoft.com/
 * This source is subject to the LinrunSpace License. Please contact ä¸Šæµ·æž—åŽŸä¿¡æ?¯ç§‘æŠ€æœ‰é™?å…¬å?¸ to get more information.
 * </copyright>
 */
package com.hankcs.hanlp.dictionary;


import com.hankcs.hanlp.HanLP;
import com.hankcs.hanlp.collection.AhoCorasick.AhoCorasickDoubleArrayTrie;
import com.hankcs.hanlp.collection.trie.DoubleArrayTrie;
import com.hankcs.hanlp.collection.trie.bintrie.BinTrie;
import com.hankcs.hanlp.corpus.io.ByteArray;
import com.hankcs.hanlp.corpus.io.IOUtil;
import com.hankcs.hanlp.corpus.tag.Nature;
import com.hankcs.hanlp.dictionary.other.CharTable;
import com.hankcs.hanlp.utility.LexiconUtility;
import com.hankcs.hanlp.utility.Predefine;
import com.hankcs.hanlp.utility.TextUtility;

import java.io.*;
import java.util.*;

import static com.hankcs.hanlp.utility.Predefine.logger;

/**
 * ç”¨æˆ·è‡ªå®šä¹‰è¯?å…¸<br>
 *     æ³¨æ„?è‡ªå®šä¹‰è¯?å…¸çš„åŠ¨æ€?å¢žåˆ æ”¹ä¸?æ˜¯çº¿ç¨‹å®‰å…¨çš„ã€‚
 *
 * @author He Han
 */
public class CustomDictionary
{
    /**
     * ç”¨äºŽå‚¨å­˜ç”¨æˆ·åŠ¨æ€?æ?’å…¥è¯?æ?¡çš„äºŒåˆ†trieæ ‘
     */
    public static BinTrie<CoreDictionary.Attribute> trie;
    public static DoubleArrayTrie<CoreDictionary.Attribute> dat = new DoubleArrayTrie<CoreDictionary.Attribute>();

    // è‡ªåŠ¨åŠ è½½è¯?å…¸
    static
    {
        String path[] = HanLP.Config.CustomDictionaryPath;
        long start = System.currentTimeMillis();
        if (!loadMainDictionary(path[0]))
        {
            logger.warning("è‡ªå®šä¹‰è¯?å…¸" + Arrays.toString(path) + "åŠ è½½å¤±è´¥");
        }
        else
        {
            logger.info("è‡ªå®šä¹‰è¯?å…¸åŠ è½½æˆ?åŠŸ:" + dat.size() + "ä¸ªè¯?æ?¡ï¼Œè€—æ—¶" + (System.currentTimeMillis() - start) + "ms");
        }
    }

    /**
     * åŠ è½½è¯?å…¸
     * @param mainPath ç¼“å­˜æ–‡ä»¶æ–‡ä»¶å??
     * @param path è‡ªå®šä¹‰è¯?å…¸
     * @param isCache æ˜¯å?¦ç¼“å­˜ç»“æžœ
     */
    public static boolean loadMainDictionary(String mainPath, String path[], DoubleArrayTrie<CoreDictionary.Attribute> dat, boolean isCache)
    {
        logger.info("è‡ªå®šä¹‰è¯?å…¸å¼€å§‹åŠ è½½:" + mainPath);
        if (loadDat(mainPath, dat)) return true;
        TreeMap<String, CoreDictionary.Attribute> map = new TreeMap<String, CoreDictionary.Attribute>();
        LinkedHashSet<Nature> customNatureCollector = new LinkedHashSet<Nature>();
        try
        {
            //String path[] = HanLP.Config.CustomDictionaryPath;
            for (String p : path)
            {
                Nature defaultNature = Nature.n;
                File file = new File(p);
                String fileName = file.getName();
                int cut = fileName.lastIndexOf(' ');
                if (cut > 0)
                {
                    // æœ‰é»˜è®¤è¯?æ€§
                    String nature = fileName.substring(cut + 1);
                    p = file.getParent() + File.separator + fileName.substring(0, cut);
                    try
                    {
                        defaultNature = LexiconUtility.convertStringToNature(nature, customNatureCollector);
                    }
                    catch (Exception e)
                    {
                        logger.severe("é…?ç½®æ–‡ä»¶ã€?" + p + "ã€‘å†™é”™äº†ï¼?" + e);
                        continue;
                    }
                }
                logger.info("ä»¥é»˜è®¤è¯?æ€§[" + defaultNature + "]åŠ è½½è‡ªå®šä¹‰è¯?å…¸" + p + "ä¸­â€¦â€¦");
                boolean success = load(p, defaultNature, map, customNatureCollector);
                if (!success) logger.warning("å¤±è´¥ï¼š" + p);
            }
            if (map.size() == 0)
            {
                logger.warning("æ²¡æœ‰åŠ è½½åˆ°ä»»ä½•è¯?æ?¡");
                map.put(Predefine.TAG_OTHER, null);     // å½“ä½œç©ºç™½å? ä½?ç¬¦
            }
            logger.info("æ­£åœ¨æž„å»ºDoubleArrayTrieâ€¦â€¦");
            dat.build(map);
            if (isCache)
            {
                // ç¼“å­˜æˆ?datæ–‡ä»¶ï¼Œä¸‹æ¬¡åŠ è½½ä¼šå¿«å¾ˆå¤š
                logger.info("æ­£åœ¨ç¼“å­˜è¯?å…¸ä¸ºdatæ–‡ä»¶â€¦â€¦");
                // ç¼“å­˜å€¼æ–‡ä»¶
                List<CoreDictionary.Attribute> attributeList = new LinkedList<CoreDictionary.Attribute>();
                for (Map.Entry<String, CoreDictionary.Attribute> entry : map.entrySet())
                {
                    attributeList.add(entry.getValue());
                }
                DataOutputStream out = new DataOutputStream(new BufferedOutputStream(IOUtil.newOutputStream(mainPath + Predefine.BIN_EXT)));
                // ç¼“å­˜ç”¨æˆ·è¯?æ€§
                if (customNatureCollector.isEmpty()) // çƒ­æ›´æ–°
                {
                    for (int i = Nature.begin.ordinal() + 1; i < Nature.values().length; ++i)
                    {
                        customNatureCollector.add(Nature.values()[i]);
                    }
                }
                IOUtil.writeCustomNature(out, customNatureCollector);
                // ç¼“å­˜æ­£æ–‡
                out.writeInt(attributeList.size());
                for (CoreDictionary.Attribute attribute : attributeList)
                {
                    attribute.save(out);
                }
                dat.save(out);
                out.close();
            }
        }
        catch (FileNotFoundException e)
        {
            logger.severe("è‡ªå®šä¹‰è¯?å…¸" + mainPath + "ä¸?å­˜åœ¨ï¼?" + e);
            return false;
        }
        catch (IOException e)
        {
            logger.severe("è‡ªå®šä¹‰è¯?å…¸" + mainPath + "è¯»å?–é”™è¯¯ï¼?" + e);
            return false;
        }
        catch (Exception e)
        {
            logger.warning("è‡ªå®šä¹‰è¯?å…¸" + mainPath + "ç¼“å­˜å¤±è´¥ï¼?\n" + TextUtility.exceptionToString(e));
        }
        return true;
    }

    private static boolean loadMainDictionary(String mainPath)
    {
        return loadMainDictionary(mainPath, HanLP.Config.CustomDictionaryPath, CustomDictionary.dat, true);
    }


    /**
     * åŠ è½½ç”¨æˆ·è¯?å…¸ï¼ˆè¿½åŠ ï¼‰
     *
     * @param path          è¯?å…¸è·¯å¾„
     * @param defaultNature é»˜è®¤è¯?æ€§
     * @param customNatureCollector æ”¶é›†ç”¨æˆ·è¯?æ€§
     * @return
     */
    public static boolean load(String path, Nature defaultNature, TreeMap<String, CoreDictionary.Attribute> map, LinkedHashSet<Nature> customNatureCollector)
    {
        try
        {
            String splitter = "\\s";
            if (path.endsWith(".csv"))
            {
                splitter = ",";
            }
            BufferedReader br = new BufferedReader(new InputStreamReader(IOUtil.newInputStream(path), "UTF-8"));
            String line;
            boolean firstLine = true;
            while ((line = br.readLine()) != null)
            {
                if (firstLine)
                {
                    line = IOUtil.removeUTF8BOM(line);
                    firstLine = false;
                }
                String[] param = line.split(splitter);
                if (param[0].length() == 0) continue;   // æŽ’é™¤ç©ºè¡Œ
                if (HanLP.Config.Normalization) param[0] = CharTable.convert(param[0]); // æ­£è§„åŒ–

                int natureCount = (param.length - 1) / 2;
                CoreDictionary.Attribute attribute;
                if (natureCount == 0)
                {
                    attribute = new CoreDictionary.Attribute(defaultNature);
                }
                else
                {
                    attribute = new CoreDictionary.Attribute(natureCount);
                    for (int i = 0; i < natureCount; ++i)
                    {
                        attribute.nature[i] = LexiconUtility.convertStringToNature(param[1 + 2 * i], customNatureCollector);
                        attribute.frequency[i] = Integer.parseInt(param[2 + 2 * i]);
                        attribute.totalFrequency += attribute.frequency[i];
                    }
                }
//                if (updateAttributeIfExist(param[0], attribute, map, rewriteTable)) continue;
                map.put(param[0], attribute);
            }
            br.close();
        }
        catch (Exception e)
        {
            logger.severe("è‡ªå®šä¹‰è¯?å…¸" + path + "è¯»å?–é”™è¯¯ï¼?" + e);
            return false;
        }

        return true;
    }

    /**
     * å¦‚æžœå·²ç»?å­˜åœ¨è¯¥è¯?æ?¡,ç›´æŽ¥æ›´æ–°è¯¥è¯?æ?¡çš„å±žæ€§
     * @param key è¯?è¯­
     * @param attribute è¯?è¯­çš„å±žæ€§
     * @param map åŠ è½½æœŸé—´çš„map
     * @param rewriteTable
     * @return æ˜¯å?¦æ›´æ–°äº†
     */
    private static boolean updateAttributeIfExist(String key, CoreDictionary.Attribute attribute, TreeMap<String, CoreDictionary.Attribute> map, TreeMap<Integer, CoreDictionary.Attribute> rewriteTable)
    {
        int wordID = CoreDictionary.getWordID(key);
        CoreDictionary.Attribute attributeExisted;
        if (wordID != -1)
        {
            attributeExisted = CoreDictionary.get(wordID);
            attributeExisted.nature = attribute.nature;
            attributeExisted.frequency = attribute.frequency;
            attributeExisted.totalFrequency = attribute.totalFrequency;
            // æ”¶é›†è¯¥è¦†å†™
            rewriteTable.put(wordID, attribute);
            return true;
        }

        attributeExisted = map.get(key);
        if (attributeExisted != null)
        {
            attributeExisted.nature = attribute.nature;
            attributeExisted.frequency = attribute.frequency;
            attributeExisted.totalFrequency = attribute.totalFrequency;
            return true;
        }

        return false;
    }

    /**
     * å¾€è‡ªå®šä¹‰è¯?å…¸ä¸­æ?’å…¥ä¸€ä¸ªæ–°è¯?ï¼ˆé?žè¦†ç›–æ¨¡å¼?ï¼‰<br>
     *     åŠ¨æ€?å¢žåˆ ä¸?ä¼šæŒ?ä¹…åŒ–åˆ°è¯?å…¸æ–‡ä»¶
     *
     * @param word                æ–°è¯? å¦‚â€œè£¸å©šâ€?
     * @param natureWithFrequency è¯?æ€§å’Œå…¶å¯¹åº”çš„é¢‘æ¬¡ï¼Œæ¯”å¦‚â€œnz 1 v 2â€?ï¼Œnullæ—¶è¡¨ç¤ºâ€œnz 1â€?
     * @return æ˜¯å?¦æ?’å…¥æˆ?åŠŸï¼ˆå¤±è´¥çš„åŽŸå› å?¯èƒ½æ˜¯ä¸?è¦†ç›–ã€?natureWithFrequencyæœ‰é—®é¢˜ç­‰ï¼Œå?Žè€…å?¯ä»¥é€šè¿‡è°ƒè¯•æ¨¡å¼?äº†è§£åŽŸå› ï¼‰
     */
    public static boolean add(String word, String natureWithFrequency)
    {
        if (contains(word)) return false;
        return insert(word, natureWithFrequency);
    }

    /**
     * å¾€è‡ªå®šä¹‰è¯?å…¸ä¸­æ?’å…¥ä¸€ä¸ªæ–°è¯?ï¼ˆé?žè¦†ç›–æ¨¡å¼?ï¼‰<br>
     *     åŠ¨æ€?å¢žåˆ ä¸?ä¼šæŒ?ä¹…åŒ–åˆ°è¯?å…¸æ–‡ä»¶
     *
     * @param word                æ–°è¯? å¦‚â€œè£¸å©šâ€?
     * @return æ˜¯å?¦æ?’å…¥æˆ?åŠŸï¼ˆå¤±è´¥çš„åŽŸå› å?¯èƒ½æ˜¯ä¸?è¦†ç›–ç­‰ï¼Œå?¯ä»¥é€šè¿‡è°ƒè¯•æ¨¡å¼?äº†è§£åŽŸå› ï¼‰
     */
    public static boolean add(String word)
    {
        if (HanLP.Config.Normalization) word = CharTable.convert(word);
        if (contains(word)) return false;
        return insert(word, null);
    }

    /**
     * å¾€è‡ªå®šä¹‰è¯?å…¸ä¸­æ?’å…¥ä¸€ä¸ªæ–°è¯?ï¼ˆè¦†ç›–æ¨¡å¼?ï¼‰<br>
     *     åŠ¨æ€?å¢žåˆ ä¸?ä¼šæŒ?ä¹…åŒ–åˆ°è¯?å…¸æ–‡ä»¶
     *
     * @param word                æ–°è¯? å¦‚â€œè£¸å©šâ€?
     * @param natureWithFrequency è¯?æ€§å’Œå…¶å¯¹åº”çš„é¢‘æ¬¡ï¼Œæ¯”å¦‚â€œnz 1 v 2â€?ï¼Œnullæ—¶è¡¨ç¤ºâ€œnz 1â€?ã€‚
     * @return æ˜¯å?¦æ?’å…¥æˆ?åŠŸï¼ˆå¤±è´¥çš„åŽŸå› å?¯èƒ½æ˜¯natureWithFrequencyé—®é¢˜ï¼Œå?¯ä»¥é€šè¿‡è°ƒè¯•æ¨¡å¼?äº†è§£åŽŸå› ï¼‰
     */
    public static boolean insert(String word, String natureWithFrequency)
    {
        if (word == null) return false;
        if (HanLP.Config.Normalization) word = CharTable.convert(word);
        CoreDictionary.Attribute att = natureWithFrequency == null ? new CoreDictionary.Attribute(Nature.nz, 1) : CoreDictionary.Attribute.create(natureWithFrequency);
        if (att == null) return false;
        if (dat.set(word, att)) return true;
        if (trie == null) trie = new BinTrie<CoreDictionary.Attribute>();
        trie.put(word, att);
        return true;
    }

    /**
     * ä»¥è¦†ç›–æ¨¡å¼?å¢žåŠ æ–°è¯?<br>
     *     åŠ¨æ€?å¢žåˆ ä¸?ä¼šæŒ?ä¹…åŒ–åˆ°è¯?å…¸æ–‡ä»¶
     *
     * @param word
     * @return
     */
    public static boolean insert(String word)
    {
        return insert(word, null);
    }

    public static boolean loadDat(String path, DoubleArrayTrie<CoreDictionary.Attribute> dat)
    {
        return loadDat(path, HanLP.Config.CustomDictionaryPath, dat);
    }

    /**
     * ä»Žç£?ç›˜åŠ è½½å?Œæ•°ç»„
     *
     * @param path ä¸»è¯?å…¸è·¯å¾„
     * @param customDicPath ç”¨æˆ·è¯?å…¸è·¯å¾„
     * @return
     */
    public static boolean loadDat(String path, String customDicPath[], DoubleArrayTrie<CoreDictionary.Attribute> dat)
    {
        try
        {
            if (isDicNeedUpdate(path, customDicPath))
            {
                return false;
            }
            ByteArray byteArray = ByteArray.createByteArray(path + Predefine.BIN_EXT);
            if (byteArray == null) return false;
            int size = byteArray.nextInt();
            if (size < 0)   // ä¸€ç§?å…¼å®¹æŽªæ–½,å½“sizeå°?äºŽé›¶è¡¨ç¤ºæ–‡ä»¶å¤´éƒ¨å‚¨å­˜äº†-sizeä¸ªç”¨æˆ·è¯?æ€§
            {
                while (++size <= 0)
                {
                    Nature.create(byteArray.nextString());
                }
                size = byteArray.nextInt();
            }
            CoreDictionary.Attribute[] attributes = new CoreDictionary.Attribute[size];
            final Nature[] natureIndexArray = Nature.values();
            for (int i = 0; i < size; ++i)
            {
                // ç¬¬ä¸€ä¸ªæ˜¯å…¨éƒ¨é¢‘æ¬¡ï¼Œç¬¬äºŒä¸ªæ˜¯è¯?æ€§ä¸ªæ•°
                int currentTotalFrequency = byteArray.nextInt();
                int length = byteArray.nextInt();
                attributes[i] = new CoreDictionary.Attribute(length);
                attributes[i].totalFrequency = currentTotalFrequency;
                for (int j = 0; j < length; ++j)
                {
                    attributes[i].nature[j] = natureIndexArray[byteArray.nextInt()];
                    attributes[i].frequency[j] = byteArray.nextInt();
                }
            }
            if (!dat.load(byteArray, attributes)) return false;
        }
        catch (Exception e)
        {
            logger.warning("è¯»å?–å¤±è´¥ï¼Œé—®é¢˜å?‘ç”Ÿåœ¨" + TextUtility.exceptionToString(e));
            return false;
        }
        return true;
    }

    /**
     * èŽ·å?–æœ¬åœ°è¯?å…¸æ›´æ–°çŠ¶æ€?
     * @return true è¡¨ç¤ºæœ¬åœ°è¯?å…¸æ¯”ç¼“å­˜æ–‡ä»¶æ–°ï¼Œéœ€è¦?åˆ é™¤ç¼“å­˜
     */
    private static boolean isDicNeedUpdate(String mainPath, String path[])
    {
        if (HanLP.Config.IOAdapter != null &&
            !HanLP.Config.IOAdapter.getClass().getName().contains("com.hankcs.hanlp.corpus.io.FileIOAdapter"))
        {
            return false;
        }
        String binPath = mainPath + Predefine.BIN_EXT;
        File binFile = new File(binPath);
        if (!binFile.exists())
        {
            return true;
        }
        long lastModified = binFile.lastModified();
        //String path[] = HanLP.Config.CustomDictionaryPath;
        for (String p : path)
        {
            File f = new File(p);
            String fileName = f.getName();
            int cut = fileName.lastIndexOf(' ');
            if (cut > 0)
            {
                p = f.getParent() + File.separator + fileName.substring(0, cut);
            }
            f = new File(p);
            if (f.exists() && f.lastModified() > lastModified)
            {
                IOUtil.deleteFile(binPath); // åˆ æŽ‰ç¼“å­˜
                logger.info("å·²æ¸…é™¤è‡ªå®šä¹‰è¯?å…¸ç¼“å­˜æ–‡ä»¶ï¼?");
                return true;
            }
        }
        return false;
    }

    /**
     * æŸ¥å?•è¯?
     *
     * @param key
     * @return
     */
    public static CoreDictionary.Attribute get(String key)
    {
        if (HanLP.Config.Normalization) key = CharTable.convert(key);
        CoreDictionary.Attribute attribute = dat.get(key);
        if (attribute != null) return attribute;
        if (trie == null) return null;
        return trie.get(key);
    }

    /**
     * åˆ é™¤å?•è¯?<br>
     *     åŠ¨æ€?å¢žåˆ ä¸?ä¼šæŒ?ä¹…åŒ–åˆ°è¯?å…¸æ–‡ä»¶
     *
     * @param key
     */
    public static void remove(String key)
    {
        if (HanLP.Config.Normalization) key = CharTable.convert(key);
        if (trie == null) return;
        trie.remove(key);
    }

    /**
     * å‰?ç¼€æŸ¥è¯¢
     *
     * @param key
     * @return
     */
    public static LinkedList<Map.Entry<String, CoreDictionary.Attribute>> commonPrefixSearch(String key)
    {
        return trie.commonPrefixSearchWithValue(key);
    }

    /**
     * å‰?ç¼€æŸ¥è¯¢
     *
     * @param chars
     * @param begin
     * @return
     */
    public static LinkedList<Map.Entry<String, CoreDictionary.Attribute>> commonPrefixSearch(char[] chars, int begin)
    {
        return trie.commonPrefixSearchWithValue(chars, begin);
    }

    public static BaseSearcher getSearcher(String text)
    {
        return new Searcher(text);
    }

    @Override
    public String toString()
    {
        return "CustomDictionary{" +
                "trie=" + trie +
                '}';
    }

    /**
     * è¯?å…¸ä¸­æ˜¯å?¦å?«æœ‰è¯?è¯­
     * @param key è¯?è¯­
     * @return æ˜¯å?¦åŒ…å?«
     */
    public static boolean contains(String key)
    {
        if (dat.exactMatchSearch(key) >= 0) return true;
        return trie != null && trie.containsKey(key);
    }

    /**
     * èŽ·å?–ä¸€ä¸ªBinTrieçš„æŸ¥è¯¢å·¥å…·
     * @param charArray æ–‡æœ¬
     * @return æŸ¥è¯¢è€…
     */
    public static BaseSearcher getSearcher(char[] charArray)
    {
        return new Searcher(charArray);
    }

    static class Searcher extends BaseSearcher<CoreDictionary.Attribute>
    {
        /**
         * åˆ†è¯?ä»Žä½•å¤„å¼€å§‹ï¼Œè¿™æ˜¯ä¸€ä¸ªçŠ¶æ€?
         */
        int begin;

        private LinkedList<Map.Entry<String, CoreDictionary.Attribute>> entryList;

        protected Searcher(char[] c)
        {
            super(c);
            entryList = new LinkedList<Map.Entry<String, CoreDictionary.Attribute>>();
        }

        protected Searcher(String text)
        {
            super(text);
            entryList = new LinkedList<Map.Entry<String, CoreDictionary.Attribute>>();
        }

        @Override
        public Map.Entry<String, CoreDictionary.Attribute> next()
        {
            // ä¿?è¯?é¦–æ¬¡è°ƒç”¨æ‰¾åˆ°ä¸€ä¸ªè¯?è¯­
            while (entryList.size() == 0 && begin < c.length)
            {
                entryList = trie.commonPrefixSearchWithValue(c, begin);
                ++begin;
            }
            // ä¹‹å?Žè°ƒç”¨ä»…åœ¨ç¼“å­˜ç”¨å®Œçš„æ—¶å€™è°ƒç”¨ä¸€æ¬¡
            if (entryList.size() == 0 && begin < c.length)
            {
                entryList = trie.commonPrefixSearchWithValue(c, begin);
                ++begin;
            }
            if (entryList.size() == 0)
            {
                return null;
            }
            Map.Entry<String, CoreDictionary.Attribute> result = entryList.getFirst();
            entryList.removeFirst();
            offset = begin - 1;
            return result;
        }
    }

    /**
     * èŽ·å?–è¯?å…¸å¯¹åº”çš„trieæ ‘
     *
     * @return
     * @deprecated è°¨æ…Žæ“?ä½œï¼Œæœ‰å?¯èƒ½åºŸå¼ƒæ­¤æŽ¥å?£
     */
    public static BinTrie<CoreDictionary.Attribute> getTrie()
    {
        return trie;
    }

    /**
     * è§£æž?ä¸€æ®µæ–‡æœ¬ï¼ˆç›®å‰?é‡‡ç”¨äº†BinTrie+DATçš„æ··å?ˆå‚¨å­˜å½¢å¼?ï¼Œæ­¤æ–¹æ³•å?¯ä»¥ç»Ÿä¸€ä¸¤ä¸ªæ•°æ?®ç»“æž„ï¼‰
     * @param text         æ–‡æœ¬
     * @param processor    å¤„ç?†å™¨
     */
    public static void parseText(char[] text, AhoCorasickDoubleArrayTrie.IHit<CoreDictionary.Attribute> processor)
    {
        if (trie != null)
        {
            trie.parseText(text, processor);
        }
        DoubleArrayTrie<CoreDictionary.Attribute>.Searcher searcher = dat.getSearcher(text, 0);
        while (searcher.next())
        {
            processor.hit(searcher.begin, searcher.begin + searcher.length, searcher.value);
        }
    }

    /**
     * è§£æž?ä¸€æ®µæ–‡æœ¬ï¼ˆç›®å‰?é‡‡ç”¨äº†BinTrie+DATçš„æ··å?ˆå‚¨å­˜å½¢å¼?ï¼Œæ­¤æ–¹æ³•å?¯ä»¥ç»Ÿä¸€ä¸¤ä¸ªæ•°æ?®ç»“æž„ï¼‰
     * @param text         æ–‡æœ¬
     * @param processor    å¤„ç?†å™¨
     */
    public static void parseText(String text, AhoCorasickDoubleArrayTrie.IHit<CoreDictionary.Attribute> processor)
    {
        if (trie != null)
        {
            BaseSearcher searcher = CustomDictionary.getSearcher(text);
            int offset;
            Map.Entry<String, CoreDictionary.Attribute> entry;
            while ((entry = searcher.next()) != null)
            {
                offset = searcher.getOffset();
                processor.hit(offset, offset + entry.getKey().length(), entry.getValue());
            }
        }
        DoubleArrayTrie<CoreDictionary.Attribute>.Searcher searcher = dat.getSearcher(text, 0);
        while (searcher.next())
        {
            processor.hit(searcher.begin, searcher.begin + searcher.length, searcher.value);
        }
    }

    /**
     * æœ€é•¿åŒ¹é…?
     *
     * @param text      æ–‡æœ¬
     * @param processor å¤„ç?†å™¨
     */
    public static void parseLongestText(String text, AhoCorasickDoubleArrayTrie.IHit<CoreDictionary.Attribute> processor)
    {
        if (trie != null)
        {
            final int[] lengthArray = new int[text.length()];
            final CoreDictionary.Attribute[] attributeArray = new CoreDictionary.Attribute[text.length()];
            char[] charArray = text.toCharArray();
            DoubleArrayTrie<CoreDictionary.Attribute>.Searcher searcher = dat.getSearcher(charArray, 0);
            while (searcher.next())
            {
                lengthArray[searcher.begin] = searcher.length;
                attributeArray[searcher.begin] = searcher.value;
            }
            trie.parseText(charArray, new AhoCorasickDoubleArrayTrie.IHit<CoreDictionary.Attribute>()
            {
                @Override
                public void hit(int begin, int end, CoreDictionary.Attribute value)
                {
                    int length = end - begin;
                    if (length > lengthArray[begin])
                    {
                        lengthArray[begin] = length;
                        attributeArray[begin] = value;
                    }
                }
            });
            for (int i = 0; i < charArray.length;)
            {
                if (lengthArray[i] == 0)
                {
                    ++i;
                }
                else
                {
                    processor.hit(i, i + lengthArray[i], attributeArray[i]);
                    i += lengthArray[i];
                }
            }
        }
        else
            dat.parseLongestText(text, processor);
    }

    /**
     * çƒ­æ›´æ–°ï¼ˆé‡?æ–°åŠ è½½ï¼‰<br>
     * é›†ç¾¤çŽ¯å¢ƒï¼ˆæˆ–å…¶ä»–IOAdapterï¼‰éœ€è¦?è‡ªè¡Œåˆ é™¤ç¼“å­˜æ–‡ä»¶ï¼ˆè·¯å¾„ = HanLP.Config.CustomDictionaryPath[0] + Predefine.BIN_EXTï¼‰
     * @return æ˜¯å?¦åŠ è½½æˆ?åŠŸ
     */
    public static boolean reload()
    {
        String path[] = HanLP.Config.CustomDictionaryPath;
        if (path == null || path.length == 0) return false;
        IOUtil.deleteFile(path[0] + Predefine.BIN_EXT); // åˆ æŽ‰ç¼“å­˜
        return loadMainDictionary(path[0]);
    }
}
