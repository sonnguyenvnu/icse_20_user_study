package com.hankcs.hanlp.mining.word;


import java.util.*;

/**
 * è¯?é¢‘-å€’æŽ’æ–‡æ¡£è¯?é¢‘ç»Ÿè®¡
 */
public class TfIdf
{

    /**
     * è¯?é¢‘ç»Ÿè®¡æ–¹å¼?
     */
    public enum TfType
    {
        /**
         * æ™®é€šè¯?é¢‘
         */
        NATURAL,
        /**
         * è¯?é¢‘çš„å¯¹æ•°å¹¶åŠ 1
         */
        LOGARITHM,
        /**
         * 01è¯?é¢‘
         */
        BOOLEAN
    }

    /**
     * tf-idf å?‘é‡?çš„æ­£è§„åŒ–ç®—æ³•
     */
    public enum Normalization
    {
        /**
         * ä¸?æ­£è§„åŒ–
         */
        NONE,
        /**
         * cosineæ­£è§„åŒ–
         */
        COSINE
    }

    /**
     * å?•æ–‡æ¡£è¯?é¢‘
     *
     * @param document è¯?è¢‹
     * @param type     è¯?é¢‘è®¡ç®—æ–¹å¼?
     * @param <TERM>   è¯?è¯­ç±»åž‹
     * @return ä¸€ä¸ªåŒ…å?«è¯?é¢‘çš„Map
     */
    public static <TERM> Map<TERM, Double> tf(Collection<TERM> document, TfType type)
    {
        Map<TERM, Double> tf = new HashMap<TERM, Double>();
        for (TERM term : document)
        {
            Double f = tf.get(term);
            if (f == null) f = 0.0;
            tf.put(term, f + 1);
        }
        if (type != TfType.NATURAL)
        {
            for (TERM term : tf.keySet())
            {
                switch (type)
                {
                    case LOGARITHM:
                        tf.put(term, 1 + Math.log(tf.get(term)));
                        break;
                    case BOOLEAN:
                        tf.put(term, tf.get(term) == 0.0 ? 0.0 : 1.0);
                        break;
                }
            }
        }
        return tf;
    }

    /**
     * å?•æ–‡æ¡£è¯?é¢‘
     *
     * @param document è¯?è¢‹
     * @param <TERM>   è¯?è¯­ç±»åž‹
     * @return ä¸€ä¸ªåŒ…å?«è¯?é¢‘çš„Map
     */
    public static <TERM> Map<TERM, Double> tf(Collection<TERM> document)
    {
        return tf(document, TfType.NATURAL);
    }

    /**
     * å¤šæ–‡æ¡£è¯?é¢‘
     *
     * @param documents å¤šä¸ªæ–‡æ¡£ï¼Œæ¯?ä¸ªæ–‡æ¡£éƒ½æ˜¯ä¸€ä¸ªè¯?è¢‹
     * @param type      è¯?é¢‘è®¡ç®—æ–¹å¼?
     * @param <TERM>    è¯?è¯­ç±»åž‹
     * @return ä¸€ä¸ªåŒ…å?«è¯?é¢‘çš„Mapçš„åˆ—è¡¨
     */
    public static <TERM> Iterable<Map<TERM, Double>> tfs(Iterable<Collection<TERM>> documents, TfType type)
    {
        List<Map<TERM, Double>> tfs = new ArrayList<Map<TERM, Double>>();
        for (Collection<TERM> document : documents)
        {
            tfs.add(tf(document, type));
        }
        return tfs;
    }

    /**
     * å¤šæ–‡æ¡£è¯?é¢‘
     *
     * @param documents å¤šä¸ªæ–‡æ¡£ï¼Œæ¯?ä¸ªæ–‡æ¡£éƒ½æ˜¯ä¸€ä¸ªè¯?è¢‹
     * @param <TERM>    è¯?è¯­ç±»åž‹
     * @return ä¸€ä¸ªåŒ…å?«è¯?é¢‘çš„Mapçš„åˆ—è¡¨
     */
    public static <TERM> Iterable<Map<TERM, Double>> tfs(Iterable<Collection<TERM>> documents)
    {
        return tfs(documents, TfType.NATURAL);
    }

    /**
     * ä¸€ç³»åˆ—æ–‡æ¡£çš„å€’æŽ’è¯?é¢‘
     *
     * @param documentVocabularies è¯?è¡¨
     * @param smooth               å¹³æ»‘å?‚æ•°ï¼Œè§†ä½œé¢?å¤–æœ‰ä¸€ä¸ªæ–‡æ¡£ï¼Œè¯¥æ–‡æ¡£å?«æœ‰smoothä¸ªæ¯?ä¸ªè¯?è¯­
     * @param addOne               tf-idfåŠ ä¸€å¹³æ»‘
     * @param <TERM>               è¯?è¯­ç±»åž‹
     * @return ä¸€ä¸ªè¯?è¯­->å€’æŽ’æ–‡æ¡£çš„Map
     */
    public static <TERM> Map<TERM, Double> idf(Iterable<Iterable<TERM>> documentVocabularies,
                                               boolean smooth, boolean addOne)
    {
        Map<TERM, Integer> df = new HashMap<TERM, Integer>();
        int d = smooth ? 1 : 0;
        int a = addOne ? 1 : 0;
        int n = d;
        for (Iterable<TERM> documentVocabulary : documentVocabularies)
        {
            n += 1;
            for (TERM term : documentVocabulary)
            {
                Integer t = df.get(term);
                if (t == null) t = d;
                df.put(term, t + 1);
            }
        }
        Map<TERM, Double> idf = new HashMap<TERM, Double>();
        for (Map.Entry<TERM, Integer> e : df.entrySet())
        {
            TERM term = e.getKey();
            double f = e.getValue();
            idf.put(term, Math.log(n / f) + a);
        }
        return idf;
    }

    /**
     * å¹³æ»‘å¤„ç?†å?Žçš„ä¸€ç³»åˆ—æ–‡æ¡£çš„å€’æŽ’è¯?é¢‘
     *
     * @param documentVocabularies è¯?è¡¨
     * @param <TERM>               è¯?è¯­ç±»åž‹
     * @return ä¸€ä¸ªè¯?è¯­->å€’æŽ’æ–‡æ¡£çš„Map
     */
    public static <TERM> Map<TERM, Double> idf(Iterable<Iterable<TERM>> documentVocabularies)
    {
        return idf(documentVocabularies, true, true);
    }

    /**
     * è®¡ç®—æ–‡æ¡£çš„tf-idf
     *
     * @param tf            è¯?é¢‘
     * @param idf           å€’æŽ’é¢‘çŽ‡
     * @param normalization æ­£è§„åŒ–
     * @param <TERM>        è¯?è¯­ç±»åž‹
     * @return ä¸€ä¸ªè¯?è¯­->tf-idfçš„Map
     */
    public static <TERM> Map<TERM, Double> tfIdf(Map<TERM, Double> tf, Map<TERM, Double> idf,
                                                 Normalization normalization)
    {
        Map<TERM, Double> tfIdf = new HashMap<TERM, Double>();
        for (TERM term : tf.keySet())
        {
            Double TF = tf.get(term);
            if (TF == null) TF = 1.;
            Double IDF = idf.get(term);
            if (IDF == null) IDF = 1.;
            tfIdf.put(term, TF * IDF);
        }
        if (normalization == Normalization.COSINE)
        {
            double n = 0.0;
            for (double x : tfIdf.values())
            {
                n += x * x;
            }
            n = Math.sqrt(n);

            for (TERM term : tfIdf.keySet())
            {
                tfIdf.put(term, tfIdf.get(term) / n);
            }
        }
        return tfIdf;
    }

    /**
     * è®¡ç®—æ–‡æ¡£çš„tf-idfï¼ˆä¸?æ­£è§„åŒ–ï¼‰
     *
     * @param tf     è¯?é¢‘
     * @param idf    å€’æŽ’é¢‘çŽ‡
     * @param <TERM> è¯?è¯­ç±»åž‹
     * @return ä¸€ä¸ªè¯?è¯­->tf-idfçš„Map
     */
    public static <TERM> Map<TERM, Double> tfIdf(Map<TERM, Double> tf, Map<TERM, Double> idf)
    {
        return tfIdf(tf, idf, Normalization.NONE);
    }

    /**
     * ä»Žè¯?é¢‘é›†å?ˆå»ºç«‹å€’æŽ’é¢‘çŽ‡
     *
     * @param tfs    æ¬¡å“?é›†å?ˆ
     * @param smooth å¹³æ»‘å?‚æ•°ï¼Œè§†ä½œé¢?å¤–æœ‰ä¸€ä¸ªæ–‡æ¡£ï¼Œè¯¥æ–‡æ¡£å?«æœ‰smoothä¸ªæ¯?ä¸ªè¯?è¯­
     * @param addOne tf-idfåŠ ä¸€å¹³æ»‘
     * @param <TERM> è¯?è¯­ç±»åž‹
     * @return ä¸€ä¸ªè¯?è¯­->å€’æŽ’æ–‡æ¡£çš„Map
     */
    public static <TERM> Map<TERM, Double> idfFromTfs(Iterable<Map<TERM, Double>> tfs, boolean smooth, boolean addOne)
    {
        return idf(new KeySetIterable<TERM, Double>(tfs), smooth, addOne);
    }

    /**
     * ä»Žè¯?é¢‘é›†å?ˆå»ºç«‹å€’æŽ’é¢‘çŽ‡ï¼ˆé»˜è®¤å¹³æ»‘è¯?é¢‘ï¼Œä¸”åŠ ä¸€å¹³æ»‘tf-idfï¼‰
     *
     * @param tfs    æ¬¡å“?é›†å?ˆ
     * @param <TERM> è¯?è¯­ç±»åž‹
     * @return ä¸€ä¸ªè¯?è¯­->å€’æŽ’æ–‡æ¡£çš„Map
     */
    public static <TERM> Map<TERM, Double> idfFromTfs(Iterable<Map<TERM, Double>> tfs)
    {
        return idfFromTfs(tfs, true, true);
    }

    /**
     * Mapçš„è¿­ä»£å™¨
     *
     * @param <KEY>   map é”®ç±»åž‹
     * @param <VALUE> map å€¼ç±»åž‹
     */
    static private class KeySetIterable<KEY, VALUE> implements Iterable<Iterable<KEY>>
    {
        final private Iterator<Map<KEY, VALUE>> maps;

        public KeySetIterable(Iterable<Map<KEY, VALUE>> maps)
        {
            this.maps = maps.iterator();
        }

        @Override
        public Iterator<Iterable<KEY>> iterator()
        {
            return new Iterator<Iterable<KEY>>()
            {
                @Override
                public boolean hasNext()
                {
                    return maps.hasNext();
                }

                @Override
                public Iterable<KEY> next()
                {
                    return maps.next().keySet();
                }

                @Override
                public void remove()
                {

                }
            };
        }
    }
}
