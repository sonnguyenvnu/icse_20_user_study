/*
 * <summary></summary>
 * <author>He Han</author>
 * <email>hankcs.cn@gmail.com</email>
 * <create-date>2014/10/29 14:53</create-date>
 *
 * <copyright file="AbstractBaseSegment.java" company="ä¸Šæµ·æž—åŽŸä¿¡æ?¯ç§‘æŠ€æœ‰é™?å…¬å?¸">
 * Copyright (c) 2003-2014, ä¸Šæµ·æž—åŽŸä¿¡æ?¯ç§‘æŠ€æœ‰é™?å…¬å?¸. All Right Reserved, http://www.linrunsoft.com/
 * This source is subject to the LinrunSpace License. Please contact ä¸Šæµ·æž—åŽŸä¿¡æ?¯ç§‘æŠ€æœ‰é™?å…¬å?¸ to get more information.
 * </copyright>
 */
package com.hankcs.hanlp.seg;

import com.hankcs.hanlp.HanLP;
import com.hankcs.hanlp.collection.AhoCorasick.AhoCorasickDoubleArrayTrie;
import com.hankcs.hanlp.collection.trie.DoubleArrayTrie;
import com.hankcs.hanlp.collection.trie.bintrie.BaseNode;
import com.hankcs.hanlp.corpus.tag.Nature;
import com.hankcs.hanlp.dictionary.CoreDictionary;
import com.hankcs.hanlp.dictionary.CustomDictionary;
import com.hankcs.hanlp.dictionary.other.CharTable;
import com.hankcs.hanlp.dictionary.other.CharType;
import com.hankcs.hanlp.seg.NShort.Path.AtomNode;
import com.hankcs.hanlp.seg.common.Term;
import com.hankcs.hanlp.seg.common.Vertex;
import com.hankcs.hanlp.seg.common.WordNet;
import com.hankcs.hanlp.utility.Predefine;
import com.hankcs.hanlp.utility.SentencesUtil;
import com.hankcs.hanlp.utility.TextUtility;

import java.util.*;

import static com.hankcs.hanlp.utility.Predefine.logger;

/**
 * åˆ†è¯?å™¨ï¼ˆåˆ†è¯?æœ?åŠ¡ï¼‰<br>
 * æ˜¯æ‰€æœ‰åˆ†è¯?å™¨çš„åŸºç±»ï¼ˆAbstractï¼‰<br>
 * åˆ†è¯?å™¨çš„åˆ†è¯?æ–¹æ³•æ˜¯çº¿ç¨‹å®‰å…¨çš„ï¼Œä½†é…?ç½®æ–¹æ³•åˆ™ä¸?ä¿?è¯?
 *
 * @author hankcs
 */
public abstract class Segment
{
    /**
     * åˆ†è¯?å™¨é…?ç½®
     */
    protected Config config;

    /**
     * æž„é€ ä¸€ä¸ªåˆ†è¯?å™¨
     */
    public Segment()
    {
        config = new Config();
    }

    /**
     * åŽŸå­?åˆ†è¯?
     *
     * @param charArray
     * @param start     ä»Žstartå¼€å§‹ï¼ˆåŒ…å?«ï¼‰
     * @param end       åˆ°endç»“æ?Ÿï¼ˆä¸?åŒ…å?«endï¼‰
     * @return ä¸€ä¸ªåˆ—è¡¨ï¼Œä»£è¡¨ä»Žstartåˆ°fromçš„æ‰€æœ‰å­—æž„æˆ?çš„åŽŸå­?èŠ‚ç‚¹
     */
    protected static List<AtomNode> atomSegment(char[] charArray, int start, int end)
    {
        List<AtomNode> atomSegment = new ArrayList<AtomNode>();
        int pCur = start, nCurType, nNextType;
        StringBuilder sb = new StringBuilder();
        char c;

        int[] charTypeArray = new int[end - start];

        // ç”Ÿæˆ?å¯¹åº”å?•ä¸ªæ±‰å­—çš„å­—ç¬¦ç±»åž‹æ•°ç»„
        for (int i = 0; i < charTypeArray.length; ++i)
        {
            c = charArray[i + start];
            charTypeArray[i] = CharType.get(c);

            if (c == '.' && i + start < (charArray.length - 1) && CharType.get(charArray[i + start + 1]) == CharType.CT_NUM)
                charTypeArray[i] = CharType.CT_NUM;
            else if (c == '.' && i + start < (charArray.length - 1) && charArray[i + start + 1] >= '0' && charArray[i + start + 1] <= '9')
                charTypeArray[i] = CharType.CT_SINGLE;
            else if (charTypeArray[i] == CharType.CT_LETTER)
                charTypeArray[i] = CharType.CT_SINGLE;
        }

        // æ ¹æ?®å­—ç¬¦ç±»åž‹æ•°ç»„ä¸­çš„å†…å®¹å®Œæˆ?åŽŸå­?åˆ‡å‰²
        while (pCur < end)
        {
            nCurType = charTypeArray[pCur - start];

            if (nCurType == CharType.CT_CHINESE || nCurType == CharType.CT_INDEX ||
                    nCurType == CharType.CT_DELIMITER || nCurType == CharType.CT_OTHER)
            {
                String single = String.valueOf(charArray[pCur]);
                if (single.length() != 0)
                    atomSegment.add(new AtomNode(single, nCurType));
                pCur++;
            }
            //å¦‚æžœæ˜¯å­—ç¬¦ã€?æ•°å­—æˆ–è€…å?Žé?¢è·Ÿéš?äº†æ•°å­—çš„å°?æ•°ç‚¹â€œ.â€?åˆ™ä¸€ç›´å?–ä¸‹åŽ»ã€‚
            else if (pCur < end - 1 && ((nCurType == CharType.CT_SINGLE) || nCurType == CharType.CT_NUM))
            {
                sb.delete(0, sb.length());
                sb.append(charArray[pCur]);

                boolean reachEnd = true;
                while (pCur < end - 1)
                {
                    nNextType = charTypeArray[++pCur - start];

                    if (nNextType == nCurType)
                        sb.append(charArray[pCur]);
                    else
                    {
                        reachEnd = false;
                        break;
                    }
                }
                atomSegment.add(new AtomNode(sb.toString(), nCurType));
                if (reachEnd)
                    pCur++;
            }
            // å¯¹äºŽæ‰€æœ‰å…¶å®ƒæƒ…å†µ
            else
            {
                atomSegment.add(new AtomNode(charArray[pCur], nCurType));
                pCur++;
            }
        }

        return atomSegment;
    }

    /**
     * ç®€æ˜“åŽŸå­?åˆ†è¯?ï¼Œå°†æ‰€æœ‰å­—æ”¾åˆ°ä¸€èµ·ä½œä¸ºä¸€ä¸ªè¯?
     *
     * @param charArray
     * @param start
     * @param end
     * @return
     */
    protected static List<AtomNode> simpleAtomSegment(char[] charArray, int start, int end)
    {
        List<AtomNode> atomNodeList = new LinkedList<AtomNode>();
        atomNodeList.add(new AtomNode(new String(charArray, start, end - start), CharType.CT_LETTER));
        return atomNodeList;
    }

    /**
     * å¿«é€ŸåŽŸå­?åˆ†è¯?ï¼Œå¸Œæœ›ç”¨è¿™ä¸ªæ–¹æ³•æ›¿æ?¢æŽ‰åŽŸæ?¥ç¼“æ…¢çš„æ–¹æ³•
     *
     * @param charArray
     * @param start
     * @param end
     * @return
     */
    protected static List<AtomNode> quickAtomSegment(char[] charArray, int start, int end)
    {
        List<AtomNode> atomNodeList = new LinkedList<AtomNode>();
        int offsetAtom = start;
        int preType = CharType.get(charArray[offsetAtom]);
        int curType;
        while (++offsetAtom < end)
        {
            curType = CharType.get(charArray[offsetAtom]);
            if (curType != preType)
            {
                // æµ®ç‚¹æ•°è¯†åˆ«
                if (preType == CharType.CT_NUM && "ï¼Œ,ï¼Ž.".indexOf(charArray[offsetAtom]) != -1)
                {
                    if (offsetAtom+1 < end)
                    {
                        int nextType = CharType.get(charArray[offsetAtom+1]);
                        if (nextType == CharType.CT_NUM)
                        {
                            continue;
                        }
                    }
                }
                atomNodeList.add(new AtomNode(new String(charArray, start, offsetAtom - start), preType));
                start = offsetAtom;
            }
            preType = curType;
        }
        if (offsetAtom == end)
            atomNodeList.add(new AtomNode(new String(charArray, start, offsetAtom - start), preType));

        return atomNodeList;
    }

    /**
     * ä½¿ç”¨ç”¨æˆ·è¯?å…¸å?ˆå¹¶ç²—åˆ†ç»“æžœ
     * @param vertexList ç²—åˆ†ç»“æžœ
     * @return å?ˆå¹¶å?Žçš„ç»“æžœ
     */
    protected static List<Vertex> combineByCustomDictionary(List<Vertex> vertexList)
    {
        return combineByCustomDictionary(vertexList, CustomDictionary.dat);
    }

    /**
     * ä½¿ç”¨ç”¨æˆ·è¯?å…¸å?ˆå¹¶ç²—åˆ†ç»“æžœ
     * @param vertexList ç²—åˆ†ç»“æžœ
     * @param dat ç”¨æˆ·è‡ªå®šä¹‰è¯?å…¸
     * @return å?ˆå¹¶å?Žçš„ç»“æžœ
     */
    protected static List<Vertex> combineByCustomDictionary(List<Vertex> vertexList, DoubleArrayTrie<CoreDictionary.Attribute> dat)
    {
        assert vertexList.size() >= 2 : "vertexListè‡³å°‘åŒ…å?« å§‹##å§‹ å’Œ æœ«##æœ«";
        Vertex[] wordNet = new Vertex[vertexList.size()];
        vertexList.toArray(wordNet);
        // DATå?ˆå¹¶
        int length = wordNet.length - 1; // è·³è¿‡é¦–å°¾
        for (int i = 1; i < length; ++i)
        {
            int state = 1;
            state = dat.transition(wordNet[i].realWord, state);
            if (state > 0)
            {
                int to = i + 1;
                int end = to;
                CoreDictionary.Attribute value = dat.output(state);
                for (; to < length; ++to)
                {
                    state = dat.transition(wordNet[to].realWord, state);
                    if (state < 0) break;
                    CoreDictionary.Attribute output = dat.output(state);
                    if (output != null)
                    {
                        value = output;
                        end = to + 1;
                    }
                }
                if (value != null)
                {
                    combineWords(wordNet, i, end, value);
                    i = end - 1;
                }
            }
        }
        // BinTrieå?ˆå¹¶
        if (CustomDictionary.trie != null)
        {
            for (int i = 1; i < length; ++i)
            {
                if (wordNet[i] == null) continue;
                BaseNode<CoreDictionary.Attribute> state = CustomDictionary.trie.transition(wordNet[i].realWord.toCharArray(), 0);
                if (state != null)
                {
                    int to = i + 1;
                    int end = to;
                    CoreDictionary.Attribute value = state.getValue();
                    for (; to < length; ++to)
                    {
                        if (wordNet[to] == null) continue;
                        state = state.transition(wordNet[to].realWord.toCharArray(), 0);
                        if (state == null) break;
                        if (state.getValue() != null)
                        {
                            value = state.getValue();
                            end = to + 1;
                        }
                    }
                    if (value != null)
                    {
                        combineWords(wordNet, i, end, value);
                        i = end - 1;
                    }
                }
            }
        }
        vertexList.clear();
        for (Vertex vertex : wordNet)
        {
            if (vertex != null) vertexList.add(vertex);
        }
        return vertexList;
    }

    /**
     * ä½¿ç”¨ç”¨æˆ·è¯?å…¸å?ˆå¹¶ç²—åˆ†ç»“æžœï¼Œå¹¶å°†ç”¨æˆ·è¯?è¯­æ”¶é›†åˆ°å…¨è¯?å›¾ä¸­
     * @param vertexList ç²—åˆ†ç»“æžœ
     * @param wordNetAll æ”¶é›†ç”¨æˆ·è¯?è¯­åˆ°å…¨è¯?å›¾ä¸­
     * @return å?ˆå¹¶å?Žçš„ç»“æžœ
     */
    protected static List<Vertex> combineByCustomDictionary(List<Vertex> vertexList, final WordNet wordNetAll)
    {
        return combineByCustomDictionary(vertexList, CustomDictionary.dat, wordNetAll);
    }

    /**
     * ä½¿ç”¨ç”¨æˆ·è¯?å…¸å?ˆå¹¶ç²—åˆ†ç»“æžœï¼Œå¹¶å°†ç”¨æˆ·è¯?è¯­æ”¶é›†åˆ°å…¨è¯?å›¾ä¸­
     * @param vertexList ç²—åˆ†ç»“æžœ
     * @param dat ç”¨æˆ·è‡ªå®šä¹‰è¯?å…¸
     * @param wordNetAll æ”¶é›†ç”¨æˆ·è¯?è¯­åˆ°å…¨è¯?å›¾ä¸­
     * @return å?ˆå¹¶å?Žçš„ç»“æžœ
     */
    protected static List<Vertex> combineByCustomDictionary(List<Vertex> vertexList, DoubleArrayTrie<CoreDictionary.Attribute> dat, final WordNet wordNetAll)
    {
        List<Vertex> outputList = combineByCustomDictionary(vertexList, dat);
        int line = 0;
        for (final Vertex vertex : outputList)
        {
            final int parentLength = vertex.realWord.length();
            final int currentLine = line;
            if (parentLength >= 3)
            {
                CustomDictionary.parseText(vertex.realWord, new AhoCorasickDoubleArrayTrie.IHit<CoreDictionary.Attribute>()
                {
                    @Override
                    public void hit(int begin, int end, CoreDictionary.Attribute value)
                    {
                        if (end - begin == parentLength) return;
                        wordNetAll.add(currentLine + begin, new Vertex(vertex.realWord.substring(begin, end), value));
                    }
                });
            }
            line += parentLength;
        }
        return outputList;
    }

    /**
     * å°†è¿žç»­çš„è¯?è¯­å?ˆå¹¶ä¸ºä¸€ä¸ª
     * @param wordNet è¯?å›¾
     * @param start èµ·å§‹ä¸‹æ ‡ï¼ˆåŒ…å?«ï¼‰
     * @param end ç»“æ?Ÿä¸‹æ ‡ï¼ˆä¸?åŒ…å?«ï¼‰
     * @param value æ–°çš„å±žæ€§
     */
    private static void combineWords(Vertex[] wordNet, int start, int end, CoreDictionary.Attribute value)
    {
        if (start + 1 == end)   // å°?ä¼˜åŒ–ï¼Œå¦‚æžœå?ªæœ‰ä¸€ä¸ªè¯?ï¼Œé‚£å°±ä¸?éœ€è¦?å?ˆå¹¶ï¼Œç›´æŽ¥åº”ç”¨æ–°å±žæ€§
        {
            wordNet[start].attribute = value;
        }
        else
        {
            StringBuilder sbTerm = new StringBuilder();
            for (int j = start; j < end; ++j)
            {
                if (wordNet[j] == null) continue;
                String realWord = wordNet[j].realWord;
                sbTerm.append(realWord);
                wordNet[j] = null;
            }
            String realWord = sbTerm.toString();
            wordNet[start] = new Vertex(realWord, realWord, value);
        }
    }

    /**
     * å°†ä¸€æ?¡è·¯å¾„è½¬ä¸ºæœ€ç»ˆç»“æžœ
     *
     * @param vertexList
     * @param offsetEnabled æ˜¯å?¦è®¡ç®—offset
     * @return
     */
    protected static List<Term> convert(List<Vertex> vertexList, boolean offsetEnabled)
    {
        assert vertexList != null;
        assert vertexList.size() >= 2 : "è¿™æ?¡è·¯å¾„ä¸?åº”å½“çŸ­äºŽ2" + vertexList.toString();
        int length = vertexList.size() - 2;
        List<Term> resultList = new ArrayList<Term>(length);
        Iterator<Vertex> iterator = vertexList.iterator();
        iterator.next();
        if (offsetEnabled)
        {
            int offset = 0;
            for (int i = 0; i < length; ++i)
            {
                Vertex vertex = iterator.next();
                Term term = convert(vertex);
                term.offset = offset;
                offset += term.length();
                resultList.add(term);
            }
        }
        else
        {
            for (int i = 0; i < length; ++i)
            {
                Vertex vertex = iterator.next();
                Term term = convert(vertex);
                resultList.add(term);
            }
        }
        return resultList;
    }

    /**
     * å°†èŠ‚ç‚¹è½¬ä¸ºterm
     *
     * @param vertex
     * @return
     */
    static Term convert(Vertex vertex)
    {
        return new Term(vertex.realWord, vertex.guessNature());
    }

    /**
     * å?ˆå¹¶æ•°å­—
     * @param termList
     */
    protected void mergeNumberQuantifier(List<Vertex> termList, WordNet wordNetAll, Config config)
    {
        if (termList.size() < 4) return;
        StringBuilder sbQuantifier = new StringBuilder();
        ListIterator<Vertex> iterator = termList.listIterator();
        iterator.next();
        int line = 1;
        while (iterator.hasNext())
        {
            Vertex pre = iterator.next();
            if (pre.hasNature(Nature.m))
            {
                sbQuantifier.append(pre.realWord);
                Vertex cur = null;
                while (iterator.hasNext() && (cur = iterator.next()).hasNature(Nature.m))
                {
                    sbQuantifier.append(cur.realWord);
                    iterator.remove();
                    removeFromWordNet(cur, wordNetAll, line, sbQuantifier.length());
                }
                if (cur != null)
                {
                    if ((cur.hasNature(Nature.q) || cur.hasNature(Nature.qv) || cur.hasNature(Nature.qt)))
                    {
                        if (config.indexMode > 0)
                        {
                            wordNetAll.add(line, new Vertex(sbQuantifier.toString(), new CoreDictionary.Attribute(Nature.m)));
                        }
                        sbQuantifier.append(cur.realWord);
                        iterator.remove();
                        removeFromWordNet(cur, wordNetAll, line, sbQuantifier.length());
                    }
                    else
                    {
                        line += cur.realWord.length();   // (cur = iterator.next()).hasNature(Nature.m) æœ€å?Žä¸€ä¸ªnextå?¯èƒ½ä¸?å?«qè¯?æ€§
                    }
                }
                if (sbQuantifier.length() != pre.realWord.length())
                {
                    for (Vertex vertex : wordNetAll.get(line + pre.realWord.length()))
                    {
                        vertex.from = null;
                    }
                    pre.realWord = sbQuantifier.toString();
                    pre.word = Predefine.TAG_NUMBER;
                    pre.attribute = new CoreDictionary.Attribute(Nature.mq);
                    pre.wordID = CoreDictionary.M_WORD_ID;
                    sbQuantifier.setLength(0);
                }
            }
            sbQuantifier.setLength(0);
            line += pre.realWord.length();
        }
//        System.out.println(wordNetAll);
    }

    /**
     * å°†ä¸€ä¸ªè¯?è¯­ä»Žè¯?ç½‘ä¸­å½»åº•æŠ¹é™¤
     * @param cur è¯?è¯­
     * @param wordNetAll è¯?ç½‘
     * @param line å½“å‰?æ‰«æ??çš„è¡Œæ•°
     * @param length å½“å‰?ç¼“å†²åŒºçš„é•¿åº¦
     */
    private static void removeFromWordNet(Vertex cur, WordNet wordNetAll, int line, int length)
    {
        LinkedList<Vertex>[] vertexes = wordNetAll.getVertexes();
        // å°†å…¶ä»ŽwordNetä¸­åˆ é™¤
        for (Vertex vertex : vertexes[line + length])
        {
            if (vertex.from == cur)
                vertex.from = null;
        }
        ListIterator<Vertex> iterator = vertexes[line + length - cur.realWord.length()].listIterator();
        while (iterator.hasNext())
        {
            Vertex vertex = iterator.next();
            if (vertex == cur) iterator.remove();
        }
    }

    /**
     * åˆ†è¯?<br>
     * æ­¤æ–¹æ³•æ˜¯çº¿ç¨‹å®‰å…¨çš„
     *
     * @param text å¾…åˆ†è¯?æ–‡æœ¬
     * @return å?•è¯?åˆ—è¡¨
     */
    public List<Term> seg(String text)
    {
        char[] charArray = text.toCharArray();
        if (HanLP.Config.Normalization)
        {
            CharTable.normalization(charArray);
        }
        if (config.threadNumber > 1 && charArray.length > 10000)    // å°?æ–‡æœ¬å¤šçº¿ç¨‹æ²¡æ„?ä¹‰ï¼Œå??è€Œå?˜æ…¢äº†
        {
            List<String> sentenceList = SentencesUtil.toSentenceList(charArray);
            String[] sentenceArray = new String[sentenceList.size()];
            sentenceList.toArray(sentenceArray);
            //noinspection unchecked
            List<Term>[] termListArray = new List[sentenceArray.length];
            final int per = sentenceArray.length / config.threadNumber;
            WorkThread[] threadArray = new WorkThread[config.threadNumber];
            for (int i = 0; i < config.threadNumber - 1; ++i)
            {
                int from = i * per;
                threadArray[i] = new WorkThread(sentenceArray, termListArray, from, from + per);
                threadArray[i].start();
            }
            threadArray[config.threadNumber - 1] = new WorkThread(sentenceArray, termListArray, (config.threadNumber - 1) * per, sentenceArray.length);
            threadArray[config.threadNumber - 1].start();
            try
            {
                for (WorkThread thread : threadArray)
                {
                    thread.join();
                }
            }
            catch (InterruptedException e)
            {
                logger.severe("çº¿ç¨‹å?Œæ­¥å¼‚å¸¸ï¼š" + TextUtility.exceptionToString(e));
                return Collections.emptyList();
            }
            List<Term> termList = new LinkedList<Term>();
            if (config.offset || config.indexMode > 0)  // ç”±äºŽåˆ†å‰²äº†å?¥å­?ï¼Œæ‰€ä»¥éœ€è¦?é‡?æ–°æ ¡æ­£offset
            {
                int sentenceOffset = 0;
                for (int i = 0; i < sentenceArray.length; ++i)
                {
                    for (Term term : termListArray[i])
                    {
                        term.offset += sentenceOffset;
                        termList.add(term);
                    }
                    sentenceOffset += sentenceArray[i].length();
                }
            }
            else
            {
                for (List<Term> list : termListArray)
                {
                    termList.addAll(list);
                }
            }

            return termList;
        }
//        if (text.length() > 10000)  // é’ˆå¯¹å¤§æ–‡æœ¬ï¼Œå…ˆæ‹†æˆ?å?¥å­?ï¼Œå?Žåˆ†è¯?ï¼Œé?¿å…?å†…å­˜å³°å€¼å¤ªå¤§
//        {
//            List<Term> termList = new LinkedList<Term>();
//            if (config.offset || config.indexMode)
//            {
//                int sentenceOffset = 0;
//                for (String sentence : SentencesUtil.toSentenceList(charArray))
//                {
//                    List<Term> termOfSentence = segSentence(sentence.toCharArray());
//                    for (Term term : termOfSentence)
//                    {
//                        term.offset += sentenceOffset;
//                        termList.add(term);
//                    }
//                    sentenceOffset += sentence.length();
//                }
//            }
//            else
//            {
//                for (String sentence : SentencesUtil.toSentenceList(charArray))
//                {
//                    termList.addAll(segSentence(sentence.toCharArray()));
//                }
//            }
//
//            return termList;
//        }
        return segSentence(charArray);
    }

    /**
     * åˆ†è¯?
     *
     * @param text å¾…åˆ†è¯?æ–‡æœ¬
     * @return å?•è¯?åˆ—è¡¨
     */
    public List<Term> seg(char[] text)
    {
        assert text != null;
        if (HanLP.Config.Normalization)
        {
            CharTable.normalization(text);
        }
        return segSentence(text);
    }

    /**
     * åˆ†è¯?æ–­å?¥ è¾“å‡ºå?¥å­?å½¢å¼?
     *
     * @param text å¾…åˆ†è¯?å?¥å­?
     * @return å?¥å­?åˆ—è¡¨ï¼Œæ¯?ä¸ªå?¥å­?ç”±ä¸€ä¸ªå?•è¯?åˆ—è¡¨ç»„æˆ?
     */
    public List<List<Term>> seg2sentence(String text)
    {
        return seg2sentence(text, true);
    }

    /**
     * åˆ†è¯?æ–­å?¥ è¾“å‡ºå?¥å­?å½¢å¼?
     *
     * @param text     å¾…åˆ†è¯?å?¥å­?
     * @param shortest æ˜¯å?¦æ–­å?¥ä¸ºæœ€ç»†çš„å­?å?¥ï¼ˆå°†é€—å?·ä¹Ÿè§†ä½œåˆ†éš”ç¬¦ï¼‰
     * @return å?¥å­?åˆ—è¡¨ï¼Œæ¯?ä¸ªå?¥å­?ç”±ä¸€ä¸ªå?•è¯?åˆ—è¡¨ç»„æˆ?
     */
    public List<List<Term>> seg2sentence(String text, boolean shortest)
    {
        List<List<Term>> resultList = new LinkedList<List<Term>>();
        {
            for (String sentence : SentencesUtil.toSentenceList(text, shortest))
            {
                resultList.add(segSentence(sentence.toCharArray()));
            }
        }

        return resultList;
    }

    /**
     * ç»™ä¸€ä¸ªå?¥å­?åˆ†è¯?
     *
     * @param sentence å¾…åˆ†è¯?å?¥å­?
     * @return å?•è¯?åˆ—è¡¨
     */
    protected abstract List<Term> segSentence(char[] sentence);

    /**
     * è®¾ä¸ºç´¢å¼•æ¨¡å¼?
     *
     * @return
     */
    public Segment enableIndexMode(boolean enable)
    {
        config.indexMode = enable ? 2 : 0;
        return this;
    }

    /**
     * ç´¢å¼•æ¨¡å¼?ä¸‹çš„æœ€å°?åˆ‡åˆ†é¢—ç²’åº¦ï¼ˆè®¾ä¸º1å?¯ä»¥æœ€å°?åˆ‡åˆ†ä¸ºå?•å­—ï¼‰
     *
     * @param minimalLength ä¸‰å­—è¯?å?Šä»¥ä¸Šçš„è¯?è¯­å°†ä¼šè¢«åˆ‡åˆ†ä¸ºå¤§äºŽç­‰äºŽæ­¤é•¿åº¦çš„å­?è¯?è¯­ã€‚é»˜è®¤å?–2ã€‚
     * @return
     */
    public Segment enableIndexMode(int minimalLength)
    {
        if (minimalLength < 1) throw new IllegalArgumentException("æœ€å°?é•¿åº¦åº”å½“å¤§äºŽç­‰äºŽ1");
        config.indexMode = minimalLength;

        return this;
    }

    /**
     * å¼€å?¯è¯?æ€§æ ‡æ³¨
     *
     * @param enable
     * @return
     */
    public Segment enablePartOfSpeechTagging(boolean enable)
    {
        config.speechTagging = enable;
        return this;
    }

    /**
     * å¼€å?¯äººå??è¯†åˆ«
     *
     * @param enable
     * @return
     */
    public Segment enableNameRecognize(boolean enable)
    {
        config.nameRecognize = enable;
        config.updateNerConfig();
        return this;
    }

    /**
     * å¼€å?¯åœ°å??è¯†åˆ«
     *
     * @param enable
     * @return
     */
    public Segment enablePlaceRecognize(boolean enable)
    {
        config.placeRecognize = enable;
        config.updateNerConfig();
        return this;
    }

    /**
     * å¼€å?¯æœºæž„å??è¯†åˆ«
     *
     * @param enable
     * @return
     */
    public Segment enableOrganizationRecognize(boolean enable)
    {
        config.organizationRecognize = enable;
        config.updateNerConfig();
        return this;
    }

    /**
     * æ˜¯å?¦å?¯ç”¨ç”¨æˆ·è¯?å…¸
     *
     * @param enable
     */
    public Segment enableCustomDictionary(boolean enable)
    {
        config.useCustomDictionary = enable;
        return this;
    }

    /**
     * æ˜¯å?¦å°½å?¯èƒ½å¼ºåˆ¶ä½¿ç”¨ç”¨æˆ·è¯?å…¸ï¼ˆä½¿ç”¨æˆ·è¯?å…¸çš„ä¼˜å…ˆçº§å°½å?¯èƒ½é«˜ï¼‰<br>
     *     è­¦å‘Šï¼šå…·ä½“å®žçŽ°ç”±å?„å­?ç±»å†³å®šï¼Œå?¯èƒ½ä¼šç ´å??åˆ†è¯?å™¨çš„ç»Ÿè®¡ç‰¹æ€§ï¼ˆä¾‹å¦‚ï¼Œå¦‚æžœç”¨æˆ·è¯?å…¸
     *     å?«æœ‰â€œå’Œæœ?â€?ï¼Œåˆ™â€œå•†å“?å’Œæœ?åŠ¡â€?çš„åˆ†è¯?ç»“æžœå?¯èƒ½ä¼šè¢«ç”¨æˆ·è¯?å…¸çš„é«˜ä¼˜å…ˆçº§å½±å“?ï¼‰ã€‚
     * @param enable
     * @return åˆ†è¯?å™¨æœ¬èº«
     *
     * @since 1.3.5
     */
    public Segment enableCustomDictionaryForcing(boolean enable)
    {
        if (enable)
        {
            enableCustomDictionary(true);
        }
        config.forceCustomDictionary = enable;
        return this;
    }

    /**
     * æ˜¯å?¦å?¯ç”¨éŸ³è¯‘äººå??è¯†åˆ«
     *
     * @param enable
     */
    public Segment enableTranslatedNameRecognize(boolean enable)
    {
        config.translatedNameRecognize = enable;
        config.updateNerConfig();
        return this;
    }

    /**
     * æ˜¯å?¦å?¯ç”¨æ—¥æœ¬äººå??è¯†åˆ«
     *
     * @param enable
     */
    public Segment enableJapaneseNameRecognize(boolean enable)
    {
        config.japaneseNameRecognize = enable;
        config.updateNerConfig();
        return this;
    }

    /**
     * æ˜¯å?¦å?¯ç”¨å??ç§»é‡?è®¡ç®—ï¼ˆå¼€å?¯å?ŽTerm.offsetæ‰?ä¼šè¢«è®¡ç®—ï¼‰
     *
     * @param enable
     * @return
     */
    public Segment enableOffset(boolean enable)
    {
        config.offset = enable;
        return this;
    }

    /**
     * æ˜¯å?¦å?¯ç”¨æ•°è¯?å’Œæ•°é‡?è¯?è¯†åˆ«<br>
     *     å?³[äºŒ, å??, ä¸€] => [äºŒå??ä¸€]ï¼Œ[å??, ä¹?, å…ƒ] => [å??ä¹?å…ƒ]
     * @param enable
     * @return
     */
    public Segment enableNumberQuantifierRecognize(boolean enable)
    {
        config.numberQuantifierRecognize = enable;
        return this;
    }

    /**
     * æ˜¯å?¦å?¯ç”¨æ‰€æœ‰çš„å‘½å??å®žä½“è¯†åˆ«
     *
     * @param enable
     * @return
     */
    public Segment enableAllNamedEntityRecognize(boolean enable)
    {
        config.nameRecognize = enable;
        config.japaneseNameRecognize = enable;
        config.translatedNameRecognize = enable;
        config.placeRecognize = enable;
        config.organizationRecognize = enable;
        config.updateNerConfig();
        return this;
    }

    class WorkThread extends Thread
    {
        String[] sentenceArray;
        List<Term>[] termListArray;
        int from;
        int to;

        public WorkThread(String[] sentenceArray, List<Term>[] termListArray, int from, int to)
        {
            this.sentenceArray = sentenceArray;
            this.termListArray = termListArray;
            this.from = from;
            this.to = to;
        }

        @Override
        public void run()
        {
            for (int i = from; i < to; ++i)
            {
                termListArray[i] = segSentence(sentenceArray[i].toCharArray());
            }
        }
    }

    /**
     * å¼€å?¯å¤šçº¿ç¨‹
     * @param enable trueè¡¨ç¤ºå¼€å?¯[ç³»ç»ŸCPUæ ¸å¿ƒæ•°]ä¸ªçº¿ç¨‹ï¼Œfalseè¡¨ç¤ºå?•çº¿ç¨‹
     * @return
     */
    public Segment enableMultithreading(boolean enable)
    {
        if (enable) config.threadNumber = Runtime.getRuntime().availableProcessors();
        else config.threadNumber = 1;
        return this;
    }

    /**
     * å¼€å?¯å¤šçº¿ç¨‹
     * @param threadNumber çº¿ç¨‹æ•°é‡?
     * @return
     */
    public Segment enableMultithreading(int threadNumber)
    {
        config.threadNumber = threadNumber;
        return this;
    }
}
